<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="关联分析       关联分析是一种在大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式:   频繁项集（frequent item sets）: 经常出现在一块的物品的集合。 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。                      相关术语        关联分析（关联规">
<meta property="og:type" content="article">
<meta property="og:title" content="第11章 使用 Apriori 算法进行关联分析">
<meta property="og:url" content="http://example.com/2021/08/11/ml_11/index.html">
<meta property="og:site_name" content="TainTear&#39;s Blog">
<meta property="og:description" content="关联分析       关联分析是一种在大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式:   频繁项集（frequent item sets）: 经常出现在一块的物品的集合。 关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。                      相关术语        关联分析（关联规">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/apachecn_apriori_homepage.jpg">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/apachecn_apriori_association_demo_1.jpg">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/apachecn_apriori_goods_all_1.jpg">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/%E9%9D%9E%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86.png">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/apachecn_association_rule_demo_1.jpg">
<meta property="og:image" content="http://example.com/2021/08/11/ml_11/img/%E6%89%80%E6%9C%89%E5%8F%AF%E8%83%BD%E7%9A%84%E9%A1%B9%E9%9B%86%E7%BB%84%E5%90%88.png">
<meta property="article:published_time" content="2021-08-10T19:07:57.000Z">
<meta property="article:modified_time" content="2021-08-28T19:36:24.236Z">
<meta property="article:author" content="TainTear">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/08/11/ml_11/img/apachecn_apriori_homepage.jpg"><title>第11章 使用 Apriori 算法进行关联分析 | TainTear's Blog</title><link ref="canonical" href="http://example.com/2021/08/11/ml_11/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">Categories</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">TainTear's Blog</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">第11章 使用 Apriori 算法进行关联分析</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-08-11</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-08-29</span></span></div></header><div class="post-body"><p><img src="img/apachecn_apriori_homepage.jpg"></p>

        <h2 id="关联分析"   >
          <a href="#关联分析" class="heading-link"><i class="fas fa-link"></i></a><a href="#关联分析" class="headerlink" title="关联分析"></a>关联分析</h2>
      <p>关联分析是一种在大规模数据集中寻找有趣关系的任务。<br>这些关系可以有两种形式: </p>
<ul>
<li>频繁项集（frequent item sets）: 经常出现在一块的物品的集合。</li>
<li>关联规则（associational rules）: 暗示两种物品之间可能存在很强的关系。</li>
</ul>

        <h2 id="相关术语"   >
          <a href="#相关术语" class="heading-link"><i class="fas fa-link"></i></a><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h2>
      <ul>
<li><p>关联分析（关联规则学习): 从大规模数据集中寻找物品间的隐含关系被称作 <code>关联分析(associati analysis)</code> 或者 <code>关联规则学习（association rule learning）</code> 。<br>下面是用一个 <code>杂货店</code> 例子来说明这两个概念，如下图所示:<br><img src="img/apachecn_apriori_association_demo_1.jpg" alt="关联分析示例1"></p>
</li>
<li><p>频繁项集: {葡萄酒, 尿布, 豆奶} 就是一个频繁项集的例子。</p>
</li>
<li><p>关联规则: 尿布 -&gt; 葡萄酒 就是一个关联规则。这意味着如果顾客买了尿布，那么他很可能会买葡萄酒。</p>
</li>
</ul>
<p>那么 <code>频繁</code> 的定义是什么呢？怎么样才算频繁呢？<br>度量它们的方法有很多种，这里我们来简单的介绍下支持度和可信度。</p>
<ul>
<li>支持度: 数据集中包含该项集的记录所占的比例。例如上图中，{豆奶} 的支持度为 4/5。{豆奶, 尿布} 的支持度为 3/5。</li>
<li>可信度: 针对一条诸如 {尿布} -&gt; {葡萄酒} 这样具体的关联规则来定义的。这条规则的 <code>可信度</code> 被定义为 <code>支持度(&#123;尿布, 葡萄酒&#125;)/支持度(&#123;尿布&#125;)</code>，从图中可以看出 支持度({尿布, 葡萄酒}) = 3/5，支持度({尿布}) = 4/5，所以 {尿布} -&gt; {葡萄酒} 的可信度 = 3/5 / 4/5 = 3/4 = 0.75。</li>
</ul>
<p><code>支持度</code> 和 <code>可信度</code> 是用来量化 <code>关联分析</code> 是否成功的一个方法。<br>假设想找到支持度大于 0.8 的所有项集，应该如何去做呢？<br>一个办法是生成一个物品所有可能组合的清单，然后对每一种组合统计它出现的频繁程度，但是当物品成千上万时，上述做法就非常非常慢了。<br>我们需要详细分析下这种情况并讨论下 Apriori 原理，该原理会减少关联规则学习时所需的计算量。</p>

        <h2 id="Apriori-原理"   >
          <a href="#Apriori-原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#Apriori-原理" class="headerlink" title="Apriori 原理"></a>Apriori 原理</h2>
      <p>假设我们一共有 4 个商品: 商品0, 商品1, 商品2, 商品3。<br>所有可能的情况如下:<br><img src="img/apachecn_apriori_goods_all_1.jpg" alt="4种商品的所有组合"><br>如果我们计算所有组合的支持度，也需要计算 15 次。即 2^N - 1 = 2^4 - 1 = 15。<br>随着物品的增加，计算的次数呈指数的形式增长 …<br>为了降低计算次数和时间，研究人员发现了一种所谓的 Apriori 原理，即某个项集是频繁的，那么它的所有子集也是频繁的。<br>例如，如果 {0, 1} 是频繁的，那么 {0}, {1} 也是频繁的。<br>该原理直观上没有什么帮助，但是如果反过来看就有用了，也就是说如果一个项集是 <code>非频繁项集</code>，那么它的所有超集也是非频繁项集，如下图所示:  </p>
<p><img src="img/%E9%9D%9E%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86.png" alt="非频繁项集"></p>
<p>在图中我们可以看到，已知灰色部分 {2,3} 是 <code>非频繁项集</code>，那么利用上面的知识，我们就可以知道 {0,2,3} {1,2,3} {0,1,2,3} 都是 <code>非频繁的</code>。<br>也就是说，计算出 {2,3} 的支持度，知道它是 <code>非频繁</code> 的之后，就不需要再计算 {0,2,3} {1,2,3} {0,1,2,3} 的支持度，因为我们知道这些集合不会满足我们的要求。<br>使用该原理就可以避免项集数目的指数增长，从而在合理的时间内计算出频繁项集。</p>
<p>Apriori 算法优缺点</p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">* 优点: 易编码实现</span><br><span class="line">* 缺点: 在大数据集上可能较慢</span><br><span class="line">* 适用数据类型: 数值型 或者 标称型数据。</span><br></pre></td></tr></table></div></figure>

<p>Apriori 算法流程步骤: </p>
<figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">* 收集数据: 使用任意方法。</span><br><span class="line">* 准备数据: 任何数据类型都可以，因为我们只保存集合。</span><br><span class="line">* 分析数据: 使用任意方法。</span><br><span class="line">* 训练数据: 使用Apiori算法来找到频繁项集。</span><br><span class="line">* 测试算法: 不需要测试过程。</span><br><span class="line">* 使用算法: 用于发现频繁项集以及物品之间的关联规则。</span><br></pre></td></tr></table></div></figure>


        <h2 id="Apriori-算法的使用"   >
          <a href="#Apriori-算法的使用" class="heading-link"><i class="fas fa-link"></i></a><a href="#Apriori-算法的使用" class="headerlink" title="Apriori 算法的使用"></a>Apriori 算法的使用</h2>
      <p>前面提到，关联分析的目标包括两项: 发现 <code>频繁项集</code> 和发现 <code>关联规则</code>。<br>首先需要找到 <code>频繁项集</code>，然后才能发现 <code>关联规则</code>。<br><code>Apriori</code> 算法是发现 <code>频繁项集</code> 的一种方法。<br>Apriori 算法的两个输入参数分别是最小支持度和数据集。<br>该算法首先会生成所有单个物品的项集列表。<br>接着扫描交易记录来查看哪些项集满足最小支持度要求，那些不满足最小支持度要求的集合会被去掉。<br>燃尽后对生下来的集合进行组合以声场包含两个元素的项集。<br>接下来再重新扫描交易记录，去掉不满足最小支持度的项集。<br>该过程重复进行直到所有项集被去掉。</p>

        <h3 id="生成候选项集"   >
          <a href="#生成候选项集" class="heading-link"><i class="fas fa-link"></i></a><a href="#生成候选项集" class="headerlink" title="生成候选项集"></a>生成候选项集</h3>
      <p>下面会创建一个用于构建初始集合的函数，也会创建一个通过扫描数据集以寻找交易记录子集的函数，<br>数据扫描的伪代码如下: </p>
<ul>
<li>对数据集中的每条交易记录 tran</li>
<li>对每个候选项集 can<ul>
<li>检查一下 can 是否是 tran 的子集: 如果是则增加 can 的计数值</li>
</ul>
</li>
<li>对每个候选项集<ul>
<li>如果其支持度不低于最小值，则保留该项集</li>
<li>返回所有频繁项集列表<br>以下是一些辅助函数。</li>
</ul>
</li>
</ul>

        <h4 id="加载数据集"   >
          <a href="#加载数据集" class="heading-link"><i class="fas fa-link"></i></a><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>():</span></span><br><span class="line">    <span class="keyword">return</span> [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">5</span>], [<span class="number">2</span>, <span class="number">5</span>]]</span><br></pre></td></tr></table></div></figure>


        <h4 id="创建集合-C1。即对-dataSet-进行去重，排序，放入-list-中，然后转换所有的元素为-frozenset"   >
          <a href="#创建集合-C1。即对-dataSet-进行去重，排序，放入-list-中，然后转换所有的元素为-frozenset" class="heading-link"><i class="fas fa-link"></i></a><a href="#创建集合-C1。即对-dataSet-进行去重，排序，放入-list-中，然后转换所有的元素为-frozenset" class="headerlink" title="创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset"></a>创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createC1</span>(<span class="params">dataSet</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;createC1（创建集合 C1）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataSet 原始数据集</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        frozenset 返回一个 frozenset 格式的 list</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    C1 = []</span><br><span class="line">    <span class="keyword">for</span> transaction <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> transaction:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> [item] <span class="keyword">in</span> C1:</span><br><span class="line">                <span class="comment"># 遍历所有的元素，如果不在 C1 出现过，那么就 append</span></span><br><span class="line">                C1.append([item])</span><br><span class="line">    <span class="comment"># 对数组进行 `从小到大` 的排序</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;sort 前=&#x27;</span>, C1</span><br><span class="line">    C1.sort()</span><br><span class="line">    <span class="comment"># frozenset 表示冻结的 set 集合，元素无改变；可以把它当字典的 key 来使用</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;sort 后=&#x27;</span>, C1</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;frozenset=&#x27;</span>, <span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">map</span>(<span class="built_in">frozenset</span>, C1)</span><br></pre></td></tr></table></div></figure>


        <h4 id="计算候选数据集-CK-在数据集-D-中的支持度，并返回支持度大于最小支持度（minSupport）的数据"   >
          <a href="#计算候选数据集-CK-在数据集-D-中的支持度，并返回支持度大于最小支持度（minSupport）的数据" class="heading-link"><i class="fas fa-link"></i></a><a href="#计算候选数据集-CK-在数据集-D-中的支持度，并返回支持度大于最小支持度（minSupport）的数据" class="headerlink" title="计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据"></a>计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanD</span>(<span class="params">D, Ck, minSupport</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;scanD（计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度 minSupport 的数据）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        D 数据集</span></span><br><span class="line"><span class="string">        Ck 候选项集列表</span></span><br><span class="line"><span class="string">        minSupport 最小支持度</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        retList 支持度大于 minSupport 的集合</span></span><br><span class="line"><span class="string">        supportData 候选项集支持度数据</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># ssCnt 临时存放选数据集 Ck 的频率. 例如: a-&gt;10, b-&gt;5, c-&gt;8</span></span><br><span class="line">    ssCnt = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> tid <span class="keyword">in</span> D:</span><br><span class="line">        <span class="keyword">for</span> can <span class="keyword">in</span> Ck:</span><br><span class="line">            <span class="comment"># s.issubset(t)  测试是否 s 中的每一个元素都在 t 中</span></span><br><span class="line">            <span class="keyword">if</span> can.issubset(tid):</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> ssCnt.has_key(can):</span><br><span class="line">                    ssCnt[can] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    ssCnt[can] += <span class="number">1</span></span><br><span class="line">    numItems = <span class="built_in">float</span>(<span class="built_in">len</span>(D)) <span class="comment"># 数据集 D 的数量</span></span><br><span class="line">    retList = []</span><br><span class="line">    supportData = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> ssCnt:</span><br><span class="line">        <span class="comment"># 支持度 = 候选项（key）出现的次数 / 所有数据集的数量</span></span><br><span class="line">        support = ssCnt[key]/numItems</span><br><span class="line">        <span class="keyword">if</span> support &gt;= minSupport:</span><br><span class="line">            <span class="comment"># 在 retList 的首位插入元素，只存储支持度满足频繁项集的值</span></span><br><span class="line">            retList.insert(<span class="number">0</span>, key)</span><br><span class="line">        <span class="comment"># 存储所有的候选项（key）和对应的支持度（support）</span></span><br><span class="line">        supportData[key] = support</span><br><span class="line">    <span class="keyword">return</span> retList, supportData</span><br></pre></td></tr></table></div></figure>

<p>完整代码地址: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/11.Apriori/apriori.py" >https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/11.Apriori/apriori.py</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h3 id="组织完整的-Apriori-算法"   >
          <a href="#组织完整的-Apriori-算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#组织完整的-Apriori-算法" class="headerlink" title="组织完整的 Apriori 算法"></a>组织完整的 Apriori 算法</h3>
      
        <h4 id="输入频繁项集列表-Lk-与返回的元素个数-k，然后输出所有可能的候选项集-Ck"   >
          <a href="#输入频繁项集列表-Lk-与返回的元素个数-k，然后输出所有可能的候选项集-Ck" class="heading-link"><i class="fas fa-link"></i></a><a href="#输入频繁项集列表-Lk-与返回的元素个数-k，然后输出所有可能的候选项集-Ck" class="headerlink" title="输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck"></a>输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aprioriGen</span>(<span class="params">Lk, k</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;aprioriGen（输入频繁项集列表 Lk 与返回的元素个数 k，然后输出候选项集 Ck。</span></span><br><span class="line"><span class="string">       例如: 以 &#123;0&#125;,&#123;1&#125;,&#123;2&#125; 为输入且 k = 2 则输出 &#123;0,1&#125;, &#123;0,2&#125;, &#123;1,2&#125;. 以 &#123;0,1&#125;,&#123;0,2&#125;,&#123;1,2&#125; 为输入且 k = 3 则输出 &#123;0,1,2&#125;</span></span><br><span class="line"><span class="string">       仅需要计算一次，不需要将所有的结果计算出来，然后进行去重操作</span></span><br><span class="line"><span class="string">       这是一个更高效的算法）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        Lk 频繁项集列表</span></span><br><span class="line"><span class="string">        k 返回的项集元素个数（若元素的前 k-2 相同，就进行合并）</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        retList 元素两两合并的数据集</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    retList = []</span><br><span class="line">    lenLk = <span class="built_in">len</span>(Lk)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(lenLk):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i+<span class="number">1</span>, lenLk):</span><br><span class="line">            L1 = <span class="built_in">list</span>(Lk[i])[: k-<span class="number">2</span>]</span><br><span class="line">            L2 = <span class="built_in">list</span>(Lk[j])[: k-<span class="number">2</span>]</span><br><span class="line">            <span class="comment"># print &#x27;-----i=&#x27;, i, k-2, Lk, Lk[i], list(Lk[i])[: k-2]</span></span><br><span class="line">            <span class="comment"># print &#x27;-----j=&#x27;, j, k-2, Lk, Lk[j], list(Lk[j])[: k-2]</span></span><br><span class="line">            L1.sort()</span><br><span class="line">            L2.sort()</span><br><span class="line">            <span class="comment"># 第一次 L1,L2 为空，元素直接进行合并，返回元素两两合并的数据集</span></span><br><span class="line">            <span class="comment"># if first k-2 elements are equal</span></span><br><span class="line">            <span class="keyword">if</span> L1 == L2:</span><br><span class="line">                <span class="comment"># set union</span></span><br><span class="line">                <span class="comment"># print &#x27;union=&#x27;, Lk[i] | Lk[j], Lk[i], Lk[j]</span></span><br><span class="line">                retList.append(Lk[i] | Lk[j])</span><br><span class="line">    <span class="keyword">return</span> retList</span><br></pre></td></tr></table></div></figure>


        <h4 id="找出数据集-dataSet-中支持度-gt-最小支持度的候选项集以及它们的支持度。即我们的频繁项集。"   >
          <a href="#找出数据集-dataSet-中支持度-gt-最小支持度的候选项集以及它们的支持度。即我们的频繁项集。" class="heading-link"><i class="fas fa-link"></i></a><a href="#找出数据集-dataSet-中支持度-gt-最小支持度的候选项集以及它们的支持度。即我们的频繁项集。" class="headerlink" title="找出数据集 dataSet 中支持度 &gt;= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。"></a>找出数据集 dataSet 中支持度 &gt;= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 找出数据集 dataSet 中支持度 &gt;= 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">apriori</span>(<span class="params">dataSet, minSupport=<span class="number">0.5</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;apriori（首先构建集合 C1，然后扫描数据集来判断这些只有一个元素的项集是否满足最小支持度的要求。那么满足最小支持度要求的项集构成集合 L1。然后 L1 中的元素相互组合成 C2，C2 再进一步过滤变成 L2，然后以此类推，知道 CN 的长度为 0 时结束，即可找出所有频繁项集的支持度。）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataSet 原始数据集</span></span><br><span class="line"><span class="string">        minSupport 支持度的阈值</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        L 频繁项集的全集</span></span><br><span class="line"><span class="string">        supportData 所有元素和支持度的全集</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># C1 即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset</span></span><br><span class="line">    C1 = createC1(dataSet)</span><br><span class="line">    <span class="comment"># 对每一行进行 set 转换，然后存放到集合中</span></span><br><span class="line">    D = <span class="built_in">map</span>(<span class="built_in">set</span>, dataSet)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;D=&#x27;</span>, D</span><br><span class="line">    <span class="comment"># 计算候选数据集 C1 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据</span></span><br><span class="line">    L1, supportData = scanD(D, C1, minSupport)</span><br><span class="line">    <span class="comment"># print &quot;L1=&quot;, L1, &quot;\n&quot;, &quot;outcome: &quot;, supportData</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># L 加了一层 list, L 一共 2 层 list</span></span><br><span class="line">    L = [L1]</span><br><span class="line">    k = <span class="number">2</span></span><br><span class="line">    <span class="comment"># 判断 L 的第 k-2 项的数据长度是否 &gt; 0。第一次执行时 L 为 [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]]。L[k-2]=L[0]=[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])]，最后面 k += 1</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">len</span>(L[k-<span class="number">2</span>]) &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;k=&#x27;</span>, k, L, L[k-<span class="number">2</span>]</span><br><span class="line">        Ck = aprioriGen(L[k-<span class="number">2</span>], k) <span class="comment"># 例如: 以 &#123;0&#125;,&#123;1&#125;,&#123;2&#125; 为输入且 k = 2 则输出 &#123;0,1&#125;, &#123;0,2&#125;, &#123;1,2&#125;. 以 &#123;0,1&#125;,&#123;0,2&#125;,&#123;1,2&#125; 为输入且 k = 3 则输出 &#123;0,1,2&#125;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Ck&#x27;</span>, Ck</span><br><span class="line"></span><br><span class="line">        Lk, supK = scanD(D, Ck, minSupport) <span class="comment"># 计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于 minSupport 的数据</span></span><br><span class="line">        <span class="comment"># 保存所有候选项集的支持度，如果字典没有，就追加元素，如果有，就更新元素</span></span><br><span class="line">        supportData.update(supK)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(Lk) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># Lk 表示满足频繁子项的集合，L 元素在增加，例如: </span></span><br><span class="line">        <span class="comment"># l=[[set(1), set(2), set(3)]]</span></span><br><span class="line">        <span class="comment"># l=[[set(1), set(2), set(3)], [set(1, 2), set(2, 3)]]</span></span><br><span class="line">        L.append(Lk)</span><br><span class="line">        k += <span class="number">1</span></span><br><span class="line">        <span class="comment"># print &#x27;k=&#x27;, k, len(L[k-2])</span></span><br><span class="line">    <span class="keyword">return</span> L, supportData</span><br></pre></td></tr></table></div></figure>

<p>到这一步，我们就找出我们所需要的 <code>频繁项集</code> 和他们的 <code>支持度</code> 了，接下来再找出关联规则即可！</p>
<p>完整代码地址: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/11.Apriori/apriori.py" >https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/11.Apriori/apriori.py</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h2 id="从频繁项集中挖掘关联规则"   >
          <a href="#从频繁项集中挖掘关联规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#从频繁项集中挖掘关联规则" class="headerlink" title="从频繁项集中挖掘关联规则"></a>从频繁项集中挖掘关联规则</h2>
      <p>前面我们介绍了用于发现 <code>频繁项集</code> 的 Apriori 算法，现在要解决的问题是如何找出 <code>关联规则</code>。</p>
<p>要找到 <code>关联规则</code>，我们首先从一个 <code>频繁项集</code> 开始。<br>我们知道集合中的元素是不重复的，但我们想知道基于这些元素能否获得其它内容。<br>某个元素或某个元素集合可能会推导出另一个元素。<br>从先前 <code>杂货店</code> 的例子可以得到，如果有一个频繁项集 {豆奶,莴苣}，那么就可能有一条关联规则 “豆奶 -&gt; 莴苣”。<br>这意味着如果有人买了豆奶，那么在统计上他会购买莴苣的概率比较大。<br>但是，这一条件反过来并不总是成立。<br>也就是说 “豆奶 -&gt; 莴苣” 统计上显著，那么 “莴苣 -&gt; 豆奶” 也不一定成立。</p>
<p>前面我们给出了 <code>频繁项集</code> 的量化定义，即它满足最小支持度要求。<br>对于 <code>关联规则</code>，我们也有类似的量化方法，这种量化指标称之为 <code>可信度</code>。<br>一条规则 A -&gt; B 的可信度定义为 support(A | B) / support(A)。（注意: 在 python 中 | 表示集合的并操作，而数学书集合并的符号是 U）。<br><code>A | B</code> 是指所有出现在集合 A 或者集合 B 中的元素。<br>由于我们先前已经计算出所有 <code>频繁项集</code> 的支持度了，现在我们要做的只不过是提取这些数据做一次除法运算即可。</p>

        <h3 id="一个频繁项集可以产生多少条关联规则呢？"   >
          <a href="#一个频繁项集可以产生多少条关联规则呢？" class="heading-link"><i class="fas fa-link"></i></a><a href="#一个频繁项集可以产生多少条关联规则呢？" class="headerlink" title="一个频繁项集可以产生多少条关联规则呢？"></a>一个频繁项集可以产生多少条关联规则呢？</h3>
      <p>如下图所示，给出的是项集 {0,1,2,3} 产生的所有关联规则:<br><img src="img/apachecn_association_rule_demo_1.jpg" alt="关联规则网格示意图"><br>与我们前面的 <code>频繁项集</code> 生成一样，我们可以为每个频繁项集产生许多关联规则。<br>如果能减少规则的数目来确保问题的可解析，那么计算起来就会好很多。<br>通过观察，我们可以知道，如果某条规则并不满足 <code>最小可信度</code> 要求，那么该规则的所有子集也不会满足 <code>最小可信度</code> 的要求。<br>如上图所示，假设 <code>123 -&gt; 3</code>  并不满足最小可信度要求，那么就知道任何左部为 {0,1,2} 子集的规则也不会满足 <code>最小可信度</code> 的要求。<br>即 <code>12 -&gt; 03</code> , <code>02 -&gt; 13</code> , <code>01 -&gt; 23</code> , <code>2 -&gt; 013</code>, <code> 1 -&gt; 023</code>, <code>0 -&gt; 123</code> 都不满足 <code>最小可信度</code> 要求。  </p>
<p>可以利用关联规则的上述性质属性来减少需要测试的规则数目，跟先前 Apriori 算法的套路一样。<br>以下是一些辅助函数: </p>

        <h4 id="计算可信度"   >
          <a href="#计算可信度" class="heading-link"><i class="fas fa-link"></i></a><a href="#计算可信度" class="headerlink" title="计算可信度"></a>计算可信度</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算可信度（confidence）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calcConf</span>(<span class="params">freqSet, H</span></span></span><br><span class="line"><span class="params"><span class="function">, supportData, brl, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;calcConf（对两个元素的频繁项，计算可信度，例如:  &#123;1,2&#125;/&#123;1&#125; 或者 &#123;1,2&#125;/&#123;2&#125; 看是否满足条件）</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        freqSet 频繁项集中的元素，例如: frozenset([1, 3])    </span></span><br><span class="line"><span class="string">        H 频繁项集中的元素的集合，例如: [frozenset([1]), frozenset([3])]</span></span><br><span class="line"><span class="string">        supportData 所有元素的支持度的字典</span></span><br><span class="line"><span class="string">        brl 关联规则列表的空数组</span></span><br><span class="line"><span class="string">        minConf 最小可信度</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        prunedH 记录 可信度大于阈值的集合</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 记录可信度大于最小可信度（minConf）的集合</span></span><br><span class="line">    prunedH = []</span><br><span class="line">    <span class="keyword">for</span> conseq <span class="keyword">in</span> H: <span class="comment"># 假设 freqSet = frozenset([1, 3]), H = [frozenset([1]), frozenset([3])]，那么现在需要求出 frozenset([1]) -&gt; frozenset([3]) 的可信度和 frozenset([3]) -&gt; frozenset([1]) 的可信度</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print &#x27;confData=&#x27;, freqSet, H, conseq, freqSet-conseq</span></span><br><span class="line">        conf = supportData[freqSet]/supportData[freqSet-conseq] <span class="comment"># 支持度定义: a -&gt; b = support(a | b) / support(a). 假设  freqSet = frozenset([1, 3]), conseq = [frozenset([1])]，那么 frozenset([1]) 至 frozenset([3]) 的可信度为 = support(a | b) / support(a) = supportData[freqSet]/supportData[freqSet-conseq] = supportData[frozenset([1, 3])] / supportData[frozenset([1])]</span></span><br><span class="line">        <span class="keyword">if</span> conf &gt;= minConf:</span><br><span class="line">            <span class="comment"># 只要买了 freqSet-conseq 集合，一定会买 conseq 集合（freqSet-conseq 集合和 conseq 集合是全集）</span></span><br><span class="line">            <span class="built_in">print</span> freqSet-conseq, <span class="string">&#x27;--&gt;&#x27;</span>, conseq, <span class="string">&#x27;conf:&#x27;</span>, conf</span><br><span class="line">            brl.append((freqSet-conseq, conseq, conf))</span><br><span class="line">            prunedH.append(conseq)</span><br><span class="line">    <span class="keyword">return</span> prunedH</span><br><span class="line">​````</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 递归计算频繁项集的规则</span></span><br><span class="line"></span><br><span class="line">​```python</span><br><span class="line"><span class="comment"># 递归计算频繁项集的规则</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rulesFromConseq</span>(<span class="params">freqSet, H, supportData, brl, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;rulesFromConseq</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        freqSet 频繁项集中的元素，例如: frozenset([2, 3, 5])    </span></span><br><span class="line"><span class="string">        H 频繁项集中的元素的集合，例如: [frozenset([2]), frozenset([3]), frozenset([5])]</span></span><br><span class="line"><span class="string">        supportData 所有元素的支持度的字典</span></span><br><span class="line"><span class="string">        brl 关联规则列表的数组</span></span><br><span class="line"><span class="string">        minConf 最小可信度</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># H[0] 是 freqSet 的元素组合的第一个元素，并且 H 中所有元素的长度都一样，长度由 aprioriGen(H, m+1) 这里的 m + 1 来控制</span></span><br><span class="line">    <span class="comment"># 该函数递归时，H[0] 的长度从 1 开始增长 1 2 3 ...</span></span><br><span class="line">    <span class="comment"># 假设 freqSet = frozenset([2, 3, 5]), H = [frozenset([2]), frozenset([3]), frozenset([5])]</span></span><br><span class="line">    <span class="comment"># 那么 m = len(H[0]) 的递归的值依次为 1 2</span></span><br><span class="line">    <span class="comment"># 在 m = 2 时, 跳出该递归。假设再递归一次，那么 H[0] = frozenset([2, 3, 5])，freqSet = frozenset([2, 3, 5]) ，没必要再计算 freqSet 与 H[0] 的关联规则了。</span></span><br><span class="line">    m = <span class="built_in">len</span>(H[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(freqSet) &gt; (m + <span class="number">1</span>)):</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;freqSet******************&#x27;</span>, <span class="built_in">len</span>(freqSet), m + <span class="number">1</span>, freqSet, H, H[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 生成 m+1 个长度的所有可能的 H 中的组合，假设 H = [frozenset([2]), frozenset([3]), frozenset([5])]</span></span><br><span class="line">        <span class="comment"># 第一次递归调用时生成 [frozenset([2, 3]), frozenset([2, 5]), frozenset([3, 5])]</span></span><br><span class="line">        <span class="comment"># 第二次 。。。没有第二次，递归条件判断时已经退出了</span></span><br><span class="line">        Hmp1 = aprioriGen(H, m+<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 返回可信度大于最小可信度的集合</span></span><br><span class="line">        Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf)</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Hmp1=&#x27;</span>, Hmp1</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;len(Hmp1)=&#x27;</span>, <span class="built_in">len</span>(Hmp1), <span class="string">&#x27;len(freqSet)=&#x27;</span>, <span class="built_in">len</span>(freqSet)</span><br><span class="line">        <span class="comment"># 计算可信度后，还有数据大于最小可信度的话，那么继续递归调用，否则跳出递归</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">len</span>(Hmp1) &gt; <span class="number">1</span>):</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;----------------------&#x27;</span>, Hmp1</span><br><span class="line">            <span class="comment"># print len(freqSet),  len(Hmp1[0]) + 1</span></span><br><span class="line">            rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf)</span><br></pre></td></tr></table></div></figure>


        <h4 id="生成关联规则"   >
          <a href="#生成关联规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#生成关联规则" class="headerlink" title="生成关联规则"></a>生成关联规则</h4>
      <figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成关联规则</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateRules</span>(<span class="params">L, supportData, minConf=<span class="number">0.7</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;generateRules</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        L 频繁项集列表</span></span><br><span class="line"><span class="string">        supportData 频繁项集支持度的字典</span></span><br><span class="line"><span class="string">        minConf 最小置信度</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        bigRuleList 可信度规则列表（关于 (A-&gt;B+置信度) 3个字段的组合）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    bigRuleList = []</span><br><span class="line">    <span class="comment"># 假设 L = [[frozenset([1]), frozenset([3]), frozenset([2]), frozenset([5])], [frozenset([1, 3]), frozenset([2, 5]), frozenset([2, 3]), frozenset([3, 5])], [frozenset([2, 3, 5])]]</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(L)):</span><br><span class="line">        <span class="comment"># 获取频繁项集中每个组合的所有元素</span></span><br><span class="line">        <span class="keyword">for</span> freqSet <span class="keyword">in</span> L[i]:</span><br><span class="line">            <span class="comment"># 假设: freqSet= frozenset([1, 3]), H1=[frozenset([1]), frozenset([3])]</span></span><br><span class="line">            <span class="comment"># 组合总的元素并遍历子元素，并转化为 frozenset 集合，再存放到 list 列表中</span></span><br><span class="line">            H1 = [<span class="built_in">frozenset</span>([item]) <span class="keyword">for</span> item <span class="keyword">in</span> freqSet]</span><br><span class="line">            <span class="comment"># 2 个的组合，走 else, 2 个以上的组合，走 if</span></span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">1</span>):</span><br><span class="line">                rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                calcConf(freqSet, H1, supportData, bigRuleList, minConf)</span><br><span class="line">    <span class="keyword">return</span> bigRuleList</span><br></pre></td></tr></table></div></figure>

<p>到这里为止，通过调用 generateRules 函数即可得出我们所需的 <code>关联规则</code>。</p>
<ul>
<li>分级法:  频繁项集-&gt;关联规则<ul>
<li>1.首先从一个频繁项集开始，接着创建一个规则列表，其中规则右部分只包含一个元素，然后对这个规则进行测试。</li>
<li>2.接下来合并所有剩余规则来创建一个新的规则列表，其中规则右部包含两个元素。</li>
<li>如下图: </li>
<li><img src="img/%E6%89%80%E6%9C%89%E5%8F%AF%E8%83%BD%E7%9A%84%E9%A1%B9%E9%9B%86%E7%BB%84%E5%90%88.png" alt="所有可能的项集组合"></li>
</ul>
</li>
<li>最后:  每次增加频繁项集的大小，Apriori 算法都会重新扫描整个数据集，是否有优化空间呢？ 下一章: FP-growth算法等着你的到来</li>
</ul>
<hr>
<ul>
<li><strong>作者: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/jiangzhonglian" >片刻</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></strong></li>
<li><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning" >GitHub地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning" >https://github.com/apachecn/AiLearning</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><strong>版权声明: 欢迎转载学习 =&gt; 请标注信息来源于 <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="http://www.apachecn.org/" >ApacheCN</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></strong></li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="http://example.com">TainTear</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="http://example.com/2021/08/11/ml_11/">http://example.com/2021/08/11/ml_11/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2021/08/12/ml_12/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">第12章 使用FP-growth算法来高效发现频繁项集</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2021/08/10/ml_10/"><span class="paginator-prev__text">第10章 K-Means（K-均值）聚类算法</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E8%81%94%E5%88%86%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">
          关联分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%9C%AF%E8%AF%AD"><span class="toc-number">2.</span> <span class="toc-text">
          相关术语</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Apriori-%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">
          Apriori 原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Apriori-%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">
          Apriori 算法的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%80%99%E9%80%89%E9%A1%B9%E9%9B%86"><span class="toc-number">4.1.</span> <span class="toc-text">
          生成候选项集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">4.1.1.</span> <span class="toc-text">
          加载数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%9B%86%E5%90%88-C1%E3%80%82%E5%8D%B3%E5%AF%B9-dataSet-%E8%BF%9B%E8%A1%8C%E5%8E%BB%E9%87%8D%EF%BC%8C%E6%8E%92%E5%BA%8F%EF%BC%8C%E6%94%BE%E5%85%A5-list-%E4%B8%AD%EF%BC%8C%E7%84%B6%E5%90%8E%E8%BD%AC%E6%8D%A2%E6%89%80%E6%9C%89%E7%9A%84%E5%85%83%E7%B4%A0%E4%B8%BA-frozenset"><span class="toc-number">4.1.2.</span> <span class="toc-text">
          创建集合 C1。即对 dataSet 进行去重，排序，放入 list 中，然后转换所有的元素为 frozenset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%80%99%E9%80%89%E6%95%B0%E6%8D%AE%E9%9B%86-CK-%E5%9C%A8%E6%95%B0%E6%8D%AE%E9%9B%86-D-%E4%B8%AD%E7%9A%84%E6%94%AF%E6%8C%81%E5%BA%A6%EF%BC%8C%E5%B9%B6%E8%BF%94%E5%9B%9E%E6%94%AF%E6%8C%81%E5%BA%A6%E5%A4%A7%E4%BA%8E%E6%9C%80%E5%B0%8F%E6%94%AF%E6%8C%81%E5%BA%A6%EF%BC%88minSupport%EF%BC%89%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">4.1.3.</span> <span class="toc-text">
          计算候选数据集 CK 在数据集 D 中的支持度，并返回支持度大于最小支持度（minSupport）的数据</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%84%E7%BB%87%E5%AE%8C%E6%95%B4%E7%9A%84-Apriori-%E7%AE%97%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">
          组织完整的 Apriori 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E5%88%97%E8%A1%A8-Lk-%E4%B8%8E%E8%BF%94%E5%9B%9E%E7%9A%84%E5%85%83%E7%B4%A0%E4%B8%AA%E6%95%B0-k%EF%BC%8C%E7%84%B6%E5%90%8E%E8%BE%93%E5%87%BA%E6%89%80%E6%9C%89%E5%8F%AF%E8%83%BD%E7%9A%84%E5%80%99%E9%80%89%E9%A1%B9%E9%9B%86-Ck"><span class="toc-number">4.2.1.</span> <span class="toc-text">
          输入频繁项集列表 Lk 与返回的元素个数 k，然后输出所有可能的候选项集 Ck</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%89%BE%E5%87%BA%E6%95%B0%E6%8D%AE%E9%9B%86-dataSet-%E4%B8%AD%E6%94%AF%E6%8C%81%E5%BA%A6-gt-%E6%9C%80%E5%B0%8F%E6%94%AF%E6%8C%81%E5%BA%A6%E7%9A%84%E5%80%99%E9%80%89%E9%A1%B9%E9%9B%86%E4%BB%A5%E5%8F%8A%E5%AE%83%E4%BB%AC%E7%9A%84%E6%94%AF%E6%8C%81%E5%BA%A6%E3%80%82%E5%8D%B3%E6%88%91%E4%BB%AC%E7%9A%84%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E3%80%82"><span class="toc-number">4.2.2.</span> <span class="toc-text">
          找出数据集 dataSet 中支持度 &gt;&#x3D; 最小支持度的候选项集以及它们的支持度。即我们的频繁项集。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8E%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E4%B8%AD%E6%8C%96%E6%8E%98%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99"><span class="toc-number">5.</span> <span class="toc-text">
          从频繁项集中挖掘关联规则</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E9%A2%91%E7%B9%81%E9%A1%B9%E9%9B%86%E5%8F%AF%E4%BB%A5%E4%BA%A7%E7%94%9F%E5%A4%9A%E5%B0%91%E6%9D%A1%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%91%A2%EF%BC%9F"><span class="toc-number">5.1.</span> <span class="toc-text">
          一个频繁项集可以产生多少条关联规则呢？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E5%8F%AF%E4%BF%A1%E5%BA%A6"><span class="toc-number">5.1.1.</span> <span class="toc-text">
          计算可信度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E6%88%90%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99"><span class="toc-number">5.1.2.</span> <span class="toc-text">
          生成关联规则</span></a></li></ol></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">18</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">2</div><div class="sidebar-ov-state-item__name">Categories</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">1</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>TainTear</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>