<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="description" content="SVD 概述       12奇异值分解（SVD, Singular Value Decomposition）:    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。                      SVD 场景        信息检索-隐性语义检索（Latent Se">
<meta property="og:type" content="article">
<meta property="og:title" content="第14章 利用SVD简化数据">
<meta property="og:url" content="http://example.com/2021/08/14/ml_14/index.html">
<meta property="og:site_name" content="TainTear&#39;s Blog">
<meta property="og:description" content="SVD 概述       12奇异值分解（SVD, Singular Value Decomposition）:    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。                      SVD 场景        信息检索-隐性语义检索（Latent Se">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/svd_headPage.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-LSI%E4%B8%BE%E4%BE%8B.png">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/SVD_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E4%B8%BB%E9%A2%98%E7%A9%BA%E9%97%B4%E6%A1%88%E4%BE%8B1.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/SVD%E5%85%AC%E5%BC%8F%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.png">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9B%B8%E4%BC%BC%E5%BA%A6.png">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F.jpg">
<meta property="og:image" content="http://example.com/2021/08/14/ml_14/img/%E5%9F%BA%E4%BA%8ESVD.png">
<meta property="article:published_time" content="2021-08-13T19:07:57.000Z">
<meta property="article:modified_time" content="2021-08-28T19:36:40.873Z">
<meta property="article:author" content="TainTear">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2021/08/14/ml_14/img/svd_headPage.jpg"><title>第14章 利用SVD简化数据 | TainTear's Blog</title><link ref="canonical" href="http://example.com/2021/08/14/ml_14/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><script>var Stun = window.Stun || {};
var CONFIG = {
  root: '/',
  algolia: undefined,
  assistSearch: undefined,
  fontIcon: {"prompt":{"success":"fas fa-check-circle","info":"fas fa-arrow-circle-right","warning":"fas fa-exclamation-circle","error":"fas fa-times-circle"},"copyBtn":"fas fa-copy"},
  sidebar: {"offsetTop":"20px","tocMaxDepth":6},
  header: {"enable":true,"showOnPost":true,"scrollDownIcon":false},
  postWidget: {"endText":true},
  nightMode: {"enable":true},
  back2top: {"enable":true},
  codeblock: {"style":"default","highlight":"light","wordWrap":false},
  reward: false,
  fancybox: false,
  zoomImage: {"gapAside":"20px"},
  galleryWaterfall: undefined,
  lazyload: false,
  pjax: undefined,
  externalLink: {"icon":{"enable":true,"name":"fas fa-external-link-alt"}},
  shortcuts: undefined,
  prompt: {"copyButton":"Copy","copySuccess":"Copy Success","copyError":"Copy Error"},
  sourcePath: {"js":"js","css":"css","images":"images"},
};

window.CONFIG = CONFIG;</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner"><nav class="header-nav header-nav--fixed"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">Home</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">Archives</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/categories/"><span class="header-nav-menu-item__icon"><i class="fas fa-layer-group"></i></span><span class="header-nav-menu-item__text">Categories</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">Tags</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav><div class="header-banner"><div class="header-banner-info"><div class="header-banner-info__title">TainTear's Blog</div><div class="header-banner-info__subtitle"></div></div></div></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><!-- Just used to judge whether it is an article page--><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">第14章 利用SVD简化数据</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">Created</span><span class="post-meta-item__value">2021-08-14</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">Updated</span><span class="post-meta-item__value">2021-08-29</span></span></div></header><div class="post-body"><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p><img src="img/svd_headPage.jpg" alt="利用SVD简化数据首页" title="利用SVD简化数据首页"></p>

        <h2 id="SVD-概述"   >
          <a href="#SVD-概述" class="heading-link"><i class="fas fa-link"></i></a><a href="#SVD-概述" class="headerlink" title="SVD 概述"></a>SVD 概述</h2>
      <figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">奇异值分解（SVD, Singular Value Decomposition）:</span><br><span class="line">    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。</span><br></pre></td></tr></table></div></figure>


        <h2 id="SVD-场景"   >
          <a href="#SVD-场景" class="heading-link"><i class="fas fa-link"></i></a><a href="#SVD-场景" class="headerlink" title="SVD 场景"></a>SVD 场景</h2>
      <blockquote>
<p>信息检索-隐性语义检索（Latent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p>
</blockquote>
<p>隐性语义索引: 矩阵 = 文档 + 词语</p>
<ul>
<li>是最早的 SVD 应用之一，我们称利用 SVD 的方法为隐性语义索引（LSI）或隐性语义分析（LSA）。</li>
</ul>
<p><img src="img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-LSI%E4%B8%BE%E4%BE%8B.png" alt="LSA举例"></p>
<blockquote>
<p>推荐系统</p>
</blockquote>
<ol>
<li>利用 SVD 从数据中构建一个主题空间。</li>
<li>再在该空间下计算其相似度。(从高维-低维空间的转化，在低维空间来计算相似度，SVD 提升了推荐系统的效率。)</li>
</ol>
<p><img src="img/SVD_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E4%B8%BB%E9%A2%98%E7%A9%BA%E9%97%B4%E6%A1%88%E4%BE%8B1.jpg" alt="主题空间案例1"></p>
<ul>
<li>上图右边标注的为一组共同特征，表示美式 BBQ 空间；另一组在上图右边未标注的为日式食品 空间。</li>
</ul>
<blockquote>
<p>图像压缩</p>
</blockquote>
<p>例如: <code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p>
<p><img src="img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg" alt="SVD公式"></p>

        <h2 id="SVD-原理"   >
          <a href="#SVD-原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#SVD-原理" class="headerlink" title="SVD 原理"></a>SVD 原理</h2>
      
        <h3 id="SVD-工作原理"   >
          <a href="#SVD-工作原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#SVD-工作原理" class="headerlink" title="SVD 工作原理"></a>SVD 工作原理</h3>
      <blockquote>
<p>矩阵分解</p>
</blockquote>
<ul>
<li>矩阵分解是将数据矩阵分解为多个独立部分的过程。</li>
<li>矩阵分解可以将原始矩阵表示成新的易于处理的形式，这种新形式是两个或多个矩阵的乘积。（类似代数中的因数分解）</li>
<li>举例: 如何将12分解成两个数的乘积？（1，12）、（2，6）、（3，4）都是合理的答案。</li>
</ul>
<blockquote>
<p>SVD 是矩阵分解的一种类型，也是矩阵分解最常见的技术</p>
</blockquote>
<ul>
<li>SVD 将原始的数据集矩阵 Data 分解成三个矩阵 U、$$\sum$$、V</li>
<li>举例: 如果原始矩阵 $$Data_{m \ast n}$$ 是m行n列，<ul>
<li>$$U_{m \ast k}$$ 表示m行k列</li>
<li>$$\sum_{k \ast k}$$ 表示k行k列</li>
<li>$$V_{k \ast n}$$ 表示k行n列。</li>
</ul>
</li>
</ul>
<p>$$Data_{m \ast n} = U_{m \ast k} \sum_{k \ast k} V_{k \ast n}$$</p>
<p><img src="img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg" alt="SVD公式"></p>
<p>具体的案例: （大家可以试着推导一下: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://wenku.baidu.com/view/b7641217866fb84ae45c8d17.html" >https://wenku.baidu.com/view/b7641217866fb84ae45c8d17.html</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> ）</p>
<p><img src="img/SVD%E5%85%AC%E5%BC%8F%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B.jpg" alt="SVD公式"></p>
<ul>
<li>上述分解中会构建出一个矩阵 $$\sum$$ ，该矩阵只有对角元素，其他元素均为0(近似于0)。另一个惯例就是，$$\sum$$ 的对角元素是从大到小排列的。这些对角元素称为奇异值。</li>
<li>奇异值与特征值(PCA 数据中重要特征)是有关系的。这里的奇异值就是矩阵 $$Data \ast Data^T$$ 特征值的平方根。</li>
<li>普遍的事实: 在某个奇异值的数目(r 个=&gt;奇异值的平方和累加到总值的90%以上)之后，其他的奇异值都置为0(近似于0)。这意味着数据集中仅有 r 个重要特征，而其余特征则都是噪声或冗余特征。</li>
</ul>

        <h3 id="SVD-算法特点"   >
          <a href="#SVD-算法特点" class="heading-link"><i class="fas fa-link"></i></a><a href="#SVD-算法特点" class="headerlink" title="SVD 算法特点"></a>SVD 算法特点</h3>
      <figure class="highlight plaintext"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">优点: 简化数据，去除噪声，优化算法的结果</span><br><span class="line">缺点: 数据的转换可能难以理解</span><br><span class="line">使用的数据类型: 数值型数据</span><br></pre></td></tr></table></div></figure>


        <h2 id="推荐系统"   >
          <a href="#推荐系统" class="heading-link"><i class="fas fa-link"></i></a><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2>
      
        <h3 id="推荐系统-概述"   >
          <a href="#推荐系统-概述" class="heading-link"><i class="fas fa-link"></i></a><a href="#推荐系统-概述" class="headerlink" title="推荐系统 概述"></a>推荐系统 概述</h3>
      <p><code>推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程。</code></p>

        <h3 id="推荐系统-场景"   >
          <a href="#推荐系统-场景" class="heading-link"><i class="fas fa-link"></i></a><a href="#推荐系统-场景" class="headerlink" title="推荐系统 场景"></a>推荐系统 场景</h3>
      <ol>
<li>Amazon 会根据顾客的购买历史向他们推荐物品</li>
<li>Netflix 会向其用户推荐电影</li>
<li>新闻网站会对用户推荐新闻频道</li>
</ol>

        <h3 id="推荐系统-要点"   >
          <a href="#推荐系统-要点" class="heading-link"><i class="fas fa-link"></i></a><a href="#推荐系统-要点" class="headerlink" title="推荐系统 要点"></a>推荐系统 要点</h3>
      <blockquote>
<p>基于协同过滤(collaborative filtering) 的推荐引擎</p>
</blockquote>
<ul>
<li>利用Python 实现 SVD(Numpy 有一个称为 linalg 的线性代数工具箱)</li>
<li>协同过滤: 是通过将用户和其他用户的数据进行对比来实现推荐的。</li>
<li>当知道了两个用户或两个物品之间的相似度，我们就可以利用已有的数据来预测未知用户的喜好。</li>
</ul>
<blockquote>
<p>基于物品的相似度和基于用户的相似度: 物品比较少则选择物品相似度，用户比较少则选择用户相似度。【矩阵还是小一点好计算】</p>
</blockquote>
<ul>
<li>基于物品的相似度: 计算物品之间的距离。【耗时会随物品数量的增加而增加】</li>
<li>由于物品A和物品C 相似度(相关度)很高，所以给买A的人推荐C。</li>
</ul>
<p><img src="img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.png" alt="SVD公式"></p>
<ul>
<li>基于用户的相似度: 计算用户之间的距离。【耗时会随用户数量的增加而增加】</li>
<li>由于用户A和用户C 相似度(相关度)很高，所以A和C是兴趣相投的人，对于C买的物品就会推荐给A。</li>
</ul>
<p><img src="img/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9B%B8%E4%BC%BC%E5%BA%A6.png" alt="SVD公式"></p>
<blockquote>
<p>相似度计算</p>
</blockquote>
<ul>
<li>inA, inB 对应的是 列向量</li>
</ul>
<ol>
<li>欧氏距离: 指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。二维或三维中的欧氏距离就是两点之间的实际距离。<ul>
<li>相似度= 1/(1+欧式距离)</li>
<li><code>相似度= 1.0/(1.0 + la.norm(inA - inB))</code></li>
<li>物品对越相似，它们的相似度值就越大。</li>
</ul>
</li>
<li>皮尔逊相关系数: 度量的是两个向量之间的相似度。<ul>
<li>相似度= 0.5 + 0.5*corrcoef() 【皮尔逊相关系数的取值范围从 -1 到 +1，通过函数0.5 + 0.5*corrcoef()这个函数计算，把值归一化到0到1之间】</li>
<li><code>相似度= 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]</code></li>
<li>相对欧氏距离的优势: 它对用户评级的量级并不敏感。</li>
</ul>
</li>
<li>余弦相似度: 计算的是两个向量夹角的余弦值。<ul>
<li>余弦值 = (A·B)/(||A||·||B||) 【余弦值的取值范围也在-1到+1之间】</li>
<li>相似度= 0.5 + 0.5*余弦值</li>
<li><code>相似度= 0.5 + 0.5*( float(inA.T*inB) / la.norm(inA)*la.norm(inB))</code></li>
<li>如果夹角为90度，则相似度为0；如果两个向量的方向相同，则相似度为1.0。</li>
</ul>
</li>
</ol>
<blockquote>
<p>推荐系统的评价</p>
</blockquote>
<ul>
<li>采用交叉测试的方法。【拆分数据为训练集和测试集】</li>
<li>推荐引擎评价的指标:  最小均方根误差(Root mean squared error, RMSE)，也称标准误差(Standard error)，就是计算均方误差的平均值然后取其平方根。<ul>
<li>如果RMSE=1, 表示相差1个星级；如果RMSE=2.5, 表示相差2.5个星级。</li>
</ul>
</li>
</ul>

        <h3 id="推荐系统-原理"   >
          <a href="#推荐系统-原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#推荐系统-原理" class="headerlink" title="推荐系统 原理"></a>推荐系统 原理</h3>
      <ul>
<li>推荐系统的工作过程: 给定一个用户，系统会为此用户返回N个最好的推荐菜。</li>
<li>实现流程大致如下: <ol>
<li>寻找用户没有评级的菜肴，即在用户-物品矩阵中的0值。</li>
<li>在用户没有评级的所有物品中，对每个物品预计一个可能的评级分数。这就是说: 我们认为用户可能会对物品的打分（这就是相似度计算的初衷）。</li>
<li>对这些物品的评分从高到低进行排序，返回前N个物品。</li>
</ol>
</li>
</ul>

        <h3 id="项目案例-餐馆菜肴推荐系统"   >
          <a href="#项目案例-餐馆菜肴推荐系统" class="heading-link"><i class="fas fa-link"></i></a><a href="#项目案例-餐馆菜肴推荐系统" class="headerlink" title="项目案例: 餐馆菜肴推荐系统"></a>项目案例: 餐馆菜肴推荐系统</h3>
      
        <h4 id="项目概述"   >
          <a href="#项目概述" class="heading-link"><i class="fas fa-link"></i></a><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h4>
      <p><code>假如一个人在家决定外出吃饭，但是他并不知道该到哪儿去吃饭，该点什么菜。推荐系统可以帮他做到这两点。</code></p>

        <h4 id="开发流程"   >
          <a href="#开发流程" class="heading-link"><i class="fas fa-link"></i></a><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h4>
      <blockquote>
<p>收集 并 准备数据</p>
</blockquote>
<p><img src="img/%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5.jpg" alt="SVD 矩阵"></p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadExData3</span>():</span></span><br><span class="line">    <span class="comment"># 利用SVD提高推荐效果，菜肴矩阵</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    行: 代表人</span></span><br><span class="line"><span class="string">    列: 代表菜肴名词</span></span><br><span class="line"><span class="string">    值: 代表人对菜肴的评分，0表示未评分</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span>[[<span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">4</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">5</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">0</span>],</span><br><span class="line">           [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">0</span>]]</span><br></pre></td></tr></table></div></figure>

<blockquote>
<p>分析数据: 这里不做过多的讨论(当然此处可以对比不同距离之间的差别)</p>
</blockquote>
<blockquote>
<p>训练算法: 通过调用 recommend() 函数进行推荐</p>
</blockquote>
<p>recommend() 会调用 基于物品相似度 或者是 基于SVD，得到推荐的物品评分。</p>
<ul>
<li>1.基于物品相似度</li>
</ul>
<p><img src="img/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.jpg" alt="基于物品相似度"></p>
<p><img src="img/%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F.jpg" alt="欧式距离的计算方式"></p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于物品相似度的推荐引擎</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">standEst</span>(<span class="params">dataMat, user, simMeas, item</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;standEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataMat         训练数据集</span></span><br><span class="line"><span class="string">        user            用户编号</span></span><br><span class="line"><span class="string">        simMeas         相似度计算方法</span></span><br><span class="line"><span class="string">        item            未评分的物品编号</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        ratSimTotal/simTotal     评分（0～5之间的值）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 得到数据集中的物品数目</span></span><br><span class="line">    n = shape(dataMat)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 初始化两个评分值</span></span><br><span class="line">    simTotal = <span class="number">0.0</span></span><br><span class="line">    ratSimTotal = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 遍历行中的每个物品（对用户评过分的物品进行遍历，并将它与其他物品进行比较）</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        userRating = dataMat[user, j]</span><br><span class="line">        <span class="comment"># 如果某个物品的评分值为0，则跳过这个物品</span></span><br><span class="line">        <span class="keyword">if</span> userRating == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 寻找两个用户都评级的物品</span></span><br><span class="line">        <span class="comment"># 变量 overLap 给出的是两个物品当中已经被评分的那个元素的索引ID</span></span><br><span class="line">        <span class="comment"># logical_and 计算x1和x2元素的真值。</span></span><br><span class="line">        overLap = nonzero(logical_and(dataMat[:, item].A &gt; <span class="number">0</span>, dataMat[:, j].A &gt; <span class="number">0</span>))[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 如果相似度为0，则两着没有任何重合元素，终止本次循环</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(overLap) == <span class="number">0</span>:</span><br><span class="line">            similarity = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 如果存在重合的物品，则基于这些重合物重新计算相似度。</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            similarity = simMeas(dataMat[overLap, item], dataMat[overLap, j])</span><br><span class="line">        <span class="comment"># print &#x27;the %d and %d similarity is : %f&#x27;(iten,j,similarity)</span></span><br><span class="line">        <span class="comment"># 相似度会不断累加，每次计算时还考虑相似度和当前用户评分的乘积</span></span><br><span class="line">        <span class="comment"># similarity  用户相似度，   userRating 用户评分</span></span><br><span class="line">        simTotal += similarity</span><br><span class="line">        ratSimTotal += similarity * userRating</span><br><span class="line">    <span class="keyword">if</span> simTotal == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 通过除以所有的评分总和，对上述相似度评分的乘积进行归一化，使得最后评分在0~5之间，这些评分用来对预测值进行排序</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ratSimTotal/simTotal</span><br></pre></td></tr></table></div></figure>

<ul>
<li>2.基于SVD(参考地址: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="http://www.codeweblog.com/svd-%E7%AC%94%E8%AE%B0/" >http://www.codeweblog.com/svd-%E7%AC%94%E8%AE%B0/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>)</li>
</ul>
<p><img src="img/%E5%9F%BA%E4%BA%8ESVD.png" alt="基于SVD.png"></p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于SVD的评分估计</span></span><br><span class="line"><span class="comment"># 在recommend() 中，这个函数用于替换对standEst()的调用，该函数对给定用户给定物品构建了一个评分估计值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">svdEst</span>(<span class="params">dataMat, user, simMeas, item</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;svdEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        dataMat         训练数据集</span></span><br><span class="line"><span class="string">        user            用户编号</span></span><br><span class="line"><span class="string">        simMeas         相似度计算方法</span></span><br><span class="line"><span class="string">        item            未评分的物品编号</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        ratSimTotal/simTotal     评分（0～5之间的值）</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 物品数目</span></span><br><span class="line">    n = shape(dataMat)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 对数据集进行SVD分解</span></span><br><span class="line">    simTotal = <span class="number">0.0</span></span><br><span class="line">    ratSimTotal = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 奇异值分解</span></span><br><span class="line">    <span class="comment"># 在SVD分解之后，我们只利用包含了90%能量值的奇异值，这些奇异值会以NumPy数组的形式得以保存</span></span><br><span class="line">    U, Sigma, VT = la.svd(dataMat)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># # 分析 Sigma 的长度取值</span></span><br><span class="line">    <span class="comment"># analyse_data(Sigma, 20)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果要进行矩阵运算，就必须要用这些奇异值构建出一个对角矩阵</span></span><br><span class="line">    Sig4 = mat(eye(<span class="number">4</span>) * Sigma[: <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 利用U矩阵将物品转换到低维空间中，构建转换后的物品(物品+4个主要的“隐形”特征)</span></span><br><span class="line">    <span class="comment"># 公式1(目的是: 降维-改变形状，也改变大小)  xformedItems = dataMat.T * U[:, :4] * Sig4.I</span></span><br><span class="line">    <span class="comment"># 公式2(目的是: 压缩-不改变形状，改变大小)      reconMat = U[:, :4] * Sig4.I * VT[:4, :]</span></span><br><span class="line">        <span class="comment"># 其中: imgCompress() 是详细的案例</span></span><br><span class="line">    <span class="comment"># 最近看到一篇文章描述，感觉挺有道理的，我就顺便补充一下注释: https://blog.csdn.net/qq_36523839/article/details/82347332</span></span><br><span class="line">    xformedItems = dataMat.T * U[:, :<span class="number">4</span>] * Sig4.I</span><br><span class="line">    <span class="comment"># 对于给定的用户，for循环在用户对应行的元素上进行遍历，</span></span><br><span class="line">    <span class="comment"># 这和standEst()函数中的for循环的目的一样，只不过这里的相似度计算时在低维空间下进行的。</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        userRating = dataMat[user, j]</span><br><span class="line">        <span class="keyword">if</span> userRating == <span class="number">0</span> <span class="keyword">or</span> j == item:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 相似度的计算方法也会作为一个参数传递给该函数</span></span><br><span class="line">        similarity = simMeas(xformedItems[item, :].T, xformedItems[j, :].T)</span><br><span class="line">        <span class="comment"># for 循环中加入了一条print语句，以便了解相似度计算的进展情况。如果觉得累赘，可以去掉</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;the %d and %d similarity is: %f&#x27;</span> % (item, j, similarity)</span><br><span class="line">        <span class="comment"># 对相似度不断累加求和</span></span><br><span class="line">        simTotal += similarity</span><br><span class="line">        <span class="comment"># 对相似度及对应评分值的乘积求和</span></span><br><span class="line">        ratSimTotal += similarity * userRating</span><br><span class="line">    <span class="keyword">if</span> simTotal == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 计算估计评分</span></span><br><span class="line">        <span class="keyword">return</span> ratSimTotal/simTotal</span><br></pre></td></tr></table></div></figure>

<p>排序获取最后的推荐结果</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># recommend()函数，就是推荐引擎，它默认调用standEst()函数，产生了最高的N个推荐结果。</span></span><br><span class="line"><span class="comment"># 如果不指定N的大小，则默认值为3。该函数另外的参数还包括相似度计算方法和估计方法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">recommend</span>(<span class="params">dataMat, user, N=<span class="number">3</span>, simMeas=cosSim, estMethod=standEst</span>):</span></span><br><span class="line">    <span class="comment"># 寻找未评级的物品</span></span><br><span class="line">    <span class="comment"># 对给定的用户建立一个未评分的物品列表</span></span><br><span class="line">    unratedItems = nonzero(dataMat[user, :].A == <span class="number">0</span>)[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 如果不存在未评分物品，那么就退出函数</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(unratedItems) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;you rated everything&#x27;</span></span><br><span class="line">    <span class="comment"># 物品的编号和评分值</span></span><br><span class="line">    itemScores = []</span><br><span class="line">    <span class="comment"># 在未评分物品上进行循环</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> unratedItems:</span><br><span class="line">        estimatedScore = estMethod(dataMat, user, simMeas, item)</span><br><span class="line">        <span class="comment"># 寻找前N个未评级物品，调用standEst()来产生该物品的预测得分，该物品的编号和估计值会放在一个元素列表itemScores中</span></span><br><span class="line">        itemScores.append((item, estimatedScore))</span><br><span class="line">        <span class="comment"># 按照估计得分，对该列表进行排序并返回。列表逆排序，第一个值就是最大值</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(itemScores, key=<span class="keyword">lambda</span> jj: jj[<span class="number">1</span>], reverse=<span class="literal">True</span>)[: N]</span><br></pre></td></tr></table></div></figure>

<blockquote>
<p>测试 和 项目调用，可直接参考我们的代码</p>
</blockquote>
<p><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py" >完整代码地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py" >https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>

        <h4 id="要点补充"   >
          <a href="#要点补充" class="heading-link"><i class="fas fa-link"></i></a><a href="#要点补充" class="headerlink" title="要点补充"></a>要点补充</h4>
      <blockquote>
<p>基于内容(content-based)的推荐</p>
</blockquote>
<ol>
<li>通过各种标签来标记菜肴</li>
<li>将这些属性作为相似度计算所需要的数据</li>
<li>这就是: 基于内容的推荐。</li>
</ol>
<blockquote>
<p>构建推荐引擎面临的挑战</p>
</blockquote>
<p>问题</p>
<ul>
<li>1）在大规模的数据集上，SVD分解会降低程序的速度</li>
<li>2）存在其他很多规模扩展性的挑战性问题，比如矩阵的表示方法和计算相似度得分消耗资源。</li>
<li>3）如何在缺乏数据时给出好的推荐-称为冷启动【简单说: 用户不会喜欢一个无效的物品，而用户不喜欢的物品又无效】</li>
</ul>
<p>建议</p>
<ul>
<li>1）在大型系统中，SVD分解(可以在程序调入时运行一次)每天运行一次或者其频率更低，并且还要离线运行。</li>
<li>2）在实际中，另一个普遍的做法就是离线计算并保存相似度得分。(物品相似度可能被用户重复的调用)</li>
<li>3）冷启动问题，解决方案就是将推荐看成是搜索问题，通过各种标签／属性特征进行<code>基于内容的推荐</code>。</li>
</ul>

        <h3 id="项目案例-基于-SVD-的图像压缩"   >
          <a href="#项目案例-基于-SVD-的图像压缩" class="heading-link"><i class="fas fa-link"></i></a><a href="#项目案例-基于-SVD-的图像压缩" class="headerlink" title="项目案例: 基于 SVD 的图像压缩"></a>项目案例: 基于 SVD 的图像压缩</h3>
      <blockquote>
<p>收集 并 准备数据</p>
</blockquote>
<p>将文本数据转化为矩阵</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载并转换数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imgLoadData</span>(<span class="params">filename</span>):</span></span><br><span class="line">    myl = []</span><br><span class="line">    <span class="comment"># 打开文本文件，并从文件以数组方式读入字符</span></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(filename).readlines():</span><br><span class="line">        newRow = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">            newRow.append(<span class="built_in">int</span>(line[i]))</span><br><span class="line">        myl.append(newRow)</span><br><span class="line">    <span class="comment"># 矩阵调入后，就可以在屏幕上输出该矩阵</span></span><br><span class="line">    myMat = mat(myl)</span><br><span class="line">    <span class="keyword">return</span> myMat</span><br></pre></td></tr></table></div></figure>

<blockquote>
<p>分析数据: 分析 Sigma 的长度个数</p>
</blockquote>
<p>通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并去除噪声。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyse_data</span>(<span class="params">Sigma, loopNum=<span class="number">20</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;analyse_data(分析 Sigma 的长度取值)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        Sigma         Sigma的值</span></span><br><span class="line"><span class="string">        loopNum       循环次数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 总方差的集合（总能量值）</span></span><br><span class="line">    Sig2 = Sigma**<span class="number">2</span></span><br><span class="line">    SigmaSum = <span class="built_in">sum</span>(Sig2)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(loopNum):</span><br><span class="line">        SigmaI = <span class="built_in">sum</span>(Sig2[:i+<span class="number">1</span>])</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        根据自己的业务情况，就行处理，设置对应的 Singma 次数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并取出噪声。</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;主成分: %s, 方差占比: %s%%&#x27;</span> % (<span class="built_in">format</span>(i+<span class="number">1</span>, <span class="string">&#x27;2.0f&#x27;</span>), <span class="built_in">format</span>(SigmaI/SigmaSum*<span class="number">100</span>, <span class="string">&#x27;4.2f&#x27;</span>))</span><br></pre></td></tr></table></div></figure>

<blockquote>
<p>使用算法: 对比使用 SVD 前后的数据差异对比，对于存储大家可以试着写写</p>
</blockquote>
<p>例如: <code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p>
<figure class="highlight python"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打印矩阵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printMat</span>(<span class="params">inMat, thresh=<span class="number">0.8</span></span>):</span></span><br><span class="line">    <span class="comment"># 由于矩阵保护了浮点数，因此定义浅色和深色，遍历所有矩阵元素，当元素大于阀值时打印1，否则打印0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">float</span>(inMat[i, k]) &gt; thresh:</span><br><span class="line">                <span class="built_in">print</span> <span class="number">1</span>,</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span> <span class="number">0</span>,</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现图像压缩，允许基于任意给定的奇异值数目来重构图像</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">imgCompress</span>(<span class="params">numSV=<span class="number">3</span>, thresh=<span class="number">0.8</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;imgCompress( )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        numSV       Sigma长度   </span></span><br><span class="line"><span class="string">        thresh      判断的阈值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 构建一个列表</span></span><br><span class="line">    myMat = imgLoadData(<span class="string">&#x27;data/14.SVD/0_5.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;****original matrix****&quot;</span></span><br><span class="line">    <span class="comment"># 对原始图像进行SVD分解并重构图像e</span></span><br><span class="line">    printMat(myMat, thresh)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过Sigma 重新构成SigRecom来实现</span></span><br><span class="line">    <span class="comment"># Sigma是一个对角矩阵，因此需要建立一个全0矩阵，然后将前面的那些奇异值填充到对角线上。</span></span><br><span class="line">    U, Sigma, VT = la.svd(myMat)</span><br><span class="line">    <span class="comment"># SigRecon = mat(zeros((numSV, numSV)))</span></span><br><span class="line">    <span class="comment"># for k in range(numSV):</span></span><br><span class="line">    <span class="comment">#     SigRecon[k, k] = Sigma[k]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分析插入的 Sigma 长度</span></span><br><span class="line">    analyse_data(Sigma, <span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">    SigRecon = mat(eye(numSV) * Sigma[: numSV])</span><br><span class="line">    reconMat = U[:, :numSV] * SigRecon * VT[:numSV, :]</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;****reconstructed matrix using %d singular values *****&quot;</span> % numSV</span><br><span class="line">    printMat(reconMat, thresh)</span><br></pre></td></tr></table></div></figure>

<p><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py" >完整代码地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py" >https://github.com/apachecn/AiLearning/blob/master/src/py2.x/ml/14.SVD/svdRecommend.py</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<hr>
<ul>
<li><strong>作者: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="http://cwiki.apachecn.org/display/~jiangzhonglian" >片刻</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span> <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="http://cwiki.apachecn.org/display/~lihuisong" >1988</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></strong></li>
<li><span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning" >GitHub地址</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>: <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="https://github.com/apachecn/AiLearning" >https://github.com/apachecn/AiLearning</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><strong>版权声明: 欢迎转载学习 =&gt; 请标注信息来源于 <span class="exturl"><a class="exturl__link"   target="_blank" rel="noopener" href="http://www.apachecn.org/" >ApacheCN</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></strong></li>
</ul>
</div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ END ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">Author: </span><span class="copyright-author__value"><a href="http://example.com">TainTear</a></span></div><div class="copyright-link"><span class="copyright-link__name">Link: </span><span class="copyright-link__value"><a href="http://example.com/2021/08/14/ml_14/">http://example.com/2021/08/14/ml_14/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">Copyright: </span><span class="copyright-notice__value">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> unless stating additionally</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://example.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><nav class="post-paginator paginator"><div class="paginator-prev"><a class="paginator-prev__link" href="/2021/08/15/ml_15/"><span class="paginator-prev__icon"><i class="fas fa-angle-left"></i></span><span class="paginator-prev__text">第15章 大数据与MapReduce</span></a></div><div class="paginator-next"><a class="paginator-next__link" href="/2021/08/13/ml_13/"><span class="paginator-prev__text">第13章 利用 PCA 来简化数据</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">Catalog</span><span class="sidebar-nav-ov">Overview</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">
          SVD 概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD-%E5%9C%BA%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">
          SVD 场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SVD-%E5%8E%9F%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">
          SVD 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SVD-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">
          SVD 工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SVD-%E7%AE%97%E6%B3%95%E7%89%B9%E7%82%B9"><span class="toc-number">3.2.</span> <span class="toc-text">
          SVD 算法特点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.</span> <span class="toc-text">
          推荐系统</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E6%A6%82%E8%BF%B0"><span class="toc-number">4.1.</span> <span class="toc-text">
          推荐系统 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%9C%BA%E6%99%AF"><span class="toc-number">4.2.</span> <span class="toc-text">
          推荐系统 场景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E8%A6%81%E7%82%B9"><span class="toc-number">4.3.</span> <span class="toc-text">
          推荐系统 要点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-%E5%8E%9F%E7%90%86"><span class="toc-number">4.4.</span> <span class="toc-text">
          推荐系统 原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E6%A1%88%E4%BE%8B-%E9%A4%90%E9%A6%86%E8%8F%9C%E8%82%B4%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.5.</span> <span class="toc-text">
          项目案例: 餐馆菜肴推荐系统</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E6%A6%82%E8%BF%B0"><span class="toc-number">4.5.1.</span> <span class="toc-text">
          项目概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B"><span class="toc-number">4.5.2.</span> <span class="toc-text">
          开发流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A6%81%E7%82%B9%E8%A1%A5%E5%85%85"><span class="toc-number">4.5.3.</span> <span class="toc-text">
          要点补充</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E6%A1%88%E4%BE%8B-%E5%9F%BA%E4%BA%8E-SVD-%E7%9A%84%E5%9B%BE%E5%83%8F%E5%8E%8B%E7%BC%A9"><span class="toc-number">4.6.</span> <span class="toc-text">
          项目案例: 基于 SVD 的图像压缩</span></a></li></ol></li></ol></section><!-- ov = overview--><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/images/icons/stun-logo.svg" alt="avatar"></div><p class="sidebar-ov-author__text">hello world</p></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">18</div><div class="sidebar-ov-state-item__name">Archives</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--categories" href="/categories/"><div class="sidebar-ov-state-item__count">2</div><div class="sidebar-ov-state-item__name">Categories</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">1</div><div class="sidebar-ov-state-item__name">Tags</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="Creative Commons" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">You have read </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2021</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>TainTear</span></div><div><span>Powered by <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a></span><span> v5.4.0</span><span class="footer__devider">|</span><span>Theme - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>